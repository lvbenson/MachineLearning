{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "For help implementing the adaboost algorithm, I used these resource to ensure I had the right parameters: https://towardsdatascience.com/adaboost-for-dummies-breaking-down-the-math-and-its-equations-into-simple-terms-87f439757dcf\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import Series, DataFrame\n",
    "import string\n",
    "\n",
    "\n",
    "letter = pd.read_csv('letter-recognition.data',header=None)\n",
    "#this is a multiclass dataset. Going to have to do some weird things to it.\n",
    "\n",
    "X1 = letter.drop(letter.columns[0], axis=1)\n",
    "y1 = letter.iloc[:,0]\n",
    "#y1 = pd.get_dummies(letter.iloc[:,0])\n",
    "y1.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('german.data-numeric',sep='\\s+',header=None)\n",
    "#credit.head()\n",
    "#good or bad credit, last column\n",
    "X2 = credit.iloc[:,:-1] # Features \n",
    "y2 = credit.iloc[:,-1] # Target \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv('spambase.data',header=None)\n",
    "#spam.head()\n",
    "#last column is spam (1) or not spam (0)\n",
    "X3 = spam.iloc[:,:-1] # Features \n",
    "y3 = spam.iloc[:,-1] # Target \n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3)"
   ]
  },
  {
   "source": [
    "#AdaBoost Algorithm "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of train =  0.6933333333333334\nAccuracy of test =  0.72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#The input of your function is the training and test sets, as well as the number of rounds of boosting T.\n",
    "\n",
    "#The function should then return the predictions of the final combined classifier on the given training and test examples, as well as the training and test #error rate of the combined classifier following each of the T rounds.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def AdaBoost_scratch(X,y, M=10, learning_rate = 1):\n",
    "    #Initialization of utility variables\n",
    "    N = len(y)\n",
    "    estimator_list, y_predict_list, estimator_error_list, estimator_weight_list, sample_weight_list = [], [],[],[],[]\n",
    "\n",
    "    #Initialize the sample weights\n",
    "    sample_weight = np.ones(N) / N\n",
    "    sample_weight_list.append(sample_weight.copy())\n",
    "\n",
    "    #For m = 1 to M\n",
    "    for m in range(M):   \n",
    "\n",
    "        #Fit a classifier\n",
    "        estimator = DecisionTreeClassifier(max_depth = 1)\n",
    "        estimator.fit(X, y, sample_weight=sample_weight)\n",
    "        y_predict = estimator.predict(X)\n",
    "\n",
    "        #Misclassifications\n",
    "        incorrect = (y_predict != y)\n",
    "\n",
    "        #Estimator error\n",
    "        estimator_error = np.mean( np.average(incorrect, weights=sample_weight, axis=0))\n",
    "        \n",
    "        #Boost estimator weights\n",
    "        estimator_weight =  learning_rate * np.log((1. - estimator_error) / estimator_error)\n",
    "\n",
    "        #Boost sample weights\n",
    "        sample_weight *= np.exp(estimator_weight * incorrect * ((sample_weight > 0) | (estimator_weight < 0)))\n",
    "\n",
    "        #Save iteration values\n",
    "        estimator_list.append(estimator)\n",
    "        y_predict_list.append(y_predict.copy())\n",
    "        estimator_error_list.append(estimator_error.copy())\n",
    "        estimator_weight_list.append(estimator_weight.copy())\n",
    "        sample_weight_list.append(sample_weight.copy())\n",
    "        \n",
    "\n",
    "\n",
    "    #Convert to np array for convenience   \n",
    "    estimator_list = np.asarray(estimator_list)\n",
    "    y_predict_list = np.asarray(y_predict_list)\n",
    "    estimator_error_list = np.asarray(estimator_error_list)\n",
    "    estimator_weight_list = np.asarray(estimator_weight_list)\n",
    "    sample_weight_list = np.asarray(sample_weight_list)\n",
    "\n",
    "    preds = (np.array([np.sign((y_predict_list[:,point] * estimator_weight_list).sum()) for point in range(N)]))\n",
    "    print('Accuracy of train = ', (preds == y).sum() / N) \n",
    "\n",
    "    return estimator_list, y_predict_list, estimator_error_list, estimator_weight_list, sample_weight_list\n",
    "\n",
    "def predictions(X,y, estimators, s_weights, e_weights):\n",
    "    N = len(y)\n",
    "    y_preds = []\n",
    "    for m,e_w in zip(estimators,e_weights):\n",
    "        estimator = DecisionTreeClassifier(max_depth = 1)\n",
    "        estimator.fit(X, y)\n",
    "        preds = estimator.predict(X)\n",
    "        y_preds.append(preds)\n",
    "\n",
    "    y_preds = np.asarray(y_preds)\n",
    "    test_preds = (np.array([np.sign((y_preds[:,point] * e_weights).sum()) for point in range(N)]))\n",
    "    print('Accuracy of test = ', (preds == y).sum() / N) \n",
    "    \n",
    "\n",
    "E, Y, EE, EW, SW = AdaBoost_scratch(X_train2,y_train2)\n",
    "predictions(X_test2,y_test2,E,SW,EW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of train =  0.6933333333333334\nAccuracy of test =  0.72\n"
     ]
    }
   ],
   "source": [
    "E, Y, EE, EW, SW = AdaBoost_scratch(X_train3,y_train3)\n",
    "predictions(X_test3,y_test3,E,SW,EW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}